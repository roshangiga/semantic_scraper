# Web Crawler Configuration
crawler:
  # Crawl4AI settings
  crawl4ai:
    verbose: true
    bypass_cache: true
    delay_before_return_html: 2
    js_only: false
    wait_for: null
    max_pages: 5000  # Maximum number of pages to crawl per domain
    exclude_section_urls: true  # Skip URLs with # fragments (e.g., #tab-categories)
    follow_pdf_redirects: true  # Follow redirects to PDF files
    max_retries: 3  # Maximum number of retries for failed pages
    retry_delay: 5  # Delay in seconds between retries
    save_checkpoint_every: 10  # Save checkpoint every N pages

  # Docling settings
  docling:
    enabled: true  # Set to false to disable Docling conversion (use raw HTML instead)
    max_file_size_mb: 10  # Maximum file size in MB for Docling conversion
    markdown:
      include_annotations: true
      mark_annotations: true
      escape_underscores: true
      image_placeholder: "<!-- image -->"
      enable_chart_tables: true
    html:
      include_annotations: true
      formula_to_mathml: true

  # File management settings
  file_manager:
    delete_existing_folders: true
    html_output_dir: "output/crawled_html"
    pages_output_dir: "output/crawled_docling"
    pdf_output_dir: "output/crawled_pdf"
    semantic_output_dir: "output/crawled_semantic"  # Directory for contextual chunks
    report_output_dir: "output/crawled_report"  # Directory for crawl reports
    filename_template: "{sanitized_url}"
    use_domain_subfolders: true  # Create subdirectories for each domain
    files_rotate: 3  # Maximum number of timestamped folders to keep before deleting oldest

  # Output formats
  output_formats:
    - "markdown"
    # - "html" # Enable if needed
    # - "docx"  # Enable if needed

# RAG (Retrieval-Augmented Generation) upload settings
rag_upload:
  enabled: false  # Set to true to enable automatic upload to RAG system
  client: "ragflow"  # RAG client to use: ragflow | defy (more coming soon)
  streaming: false  # When enabled=true: true=real-time upload, false=batch upload at end
  source: "output/crawled_semantic"  # Path to read from


# Contextual chunking settings
contextual_chunking:
  enabled: false
  provider: "gemini"  # openai | azure | gemini | spacy

  # Models per provider
  openai_model: "gpt-4o-mini"
  gemini_model: "gemini-2.5-flash"
  spacy_model: "en_core_web_trf"  # SpaCy transformer model for semantic chunking

  azure_endpoint: "https://scrapper-resource2025.cognitiveservices.azure.com/"
  azure_api_version: "2024-12-01-preview"
  azure_deployment: "gpt-5-mini"

# Parallel processing settings
semantic_workers: 1  # Number of parallel workers for semantic processing (default: 1)


# Global HTML cleaning settings (applied to all domains)
html_cleaning:
  remove_css_hidden_elements: true  # Remove elements hidden by CSS styles (display:none, visibility:hidden)
  html_elements_to_remove:
    - "head"
    - "header"
    - "footer"
    - "nav"
    - "aside"
  html_classes_to_remove:
    - ".sidebar"
    - ".navbar"
    - ".header"
    - ".footer"
    - ".hidden"
    - ".hide"
    - ".d-none"
    - ".invisible"
    - ".sr-only"
    - ".screen-reader-only"
    - "[style*='display: none']"
    - "[style*='display:none']"
    - "[style*='visibility: hidden']"
    - "[style*='visibility:hidden']"
  comment_blocks_to_remove:
    - [ "<!-- Cookie -->", "<!-- Cookie -->" ]
    - [ "<!-- Footer Content -->", "<!-- End Footer Content -->" ]
    - [ "<!-- Copyright Footer -->", "<!-- End Copyright Footer -->" ]
    - [ "<!-- start banner -->", "<!-- end banner -->" ]
    - [ "<!-- start scroll progress -->", "<!-- end scroll progress -->" ]
    - [ "<!-- start header -->", "<!-- start section -->" ]
    - [ "<!-- card-mobile -->", "<!-- End card-mobile -->" ]

# Markdown post-processing settings
markdown_processing:
  remove_duplicate_files: true  # Remove duplicate files based on content (excluding Source: line)
  remove_blank_files: true  # Remove markdown files that only contain the Source: line
  sections_to_ignore:
    - "How can we help you?"
    - "Contact Us"
    - "Infos"
    - "Quick links"
    - "Shop by products &amp; services"
    - "my.t support"
    - "Related Products"
    # Add more section titles to ignore here
    # Examples:updatte
    # - "Contact Us"
    # - "Related Articles"

# Link processing settings
link_processing:
  exclude_image_extensions:
    - ".jpg"
    - ".jpeg"
    - ".png"
    - ".gif"
    - ".bmp"
    - ".svg"
    - ".webp"
    - ".ico"
  exclude_section_urls: true  # URLs containing #
  convert_relative_to_absolute: true
  process_pdf_links: true  # Download and extract PDF content
  exclude_urls:  # Global URL patterns to exclude
    - "**/login"
    # Add more URL patterns to exclude here

# Domain-specific configurations
domains:
  - domain: "myt.mu"
    start_urls:
      - "https://myt.mu/"
    js_code: |
      // Remove unwanted elements
      document.querySelectorAll('header, footer, nav, aside, .sidebar, .navbar, .header, .footer, style, script').forEach(el => el.remove());
      
      // Detect if we're on a PDF page and add metadata
      if (window.location.href.includes('.pdf')) {
        // Create a marker element that indicates this is a PDF redirect
        const marker = document.createElement('div');
        marker.id = 'pdf-redirect-marker';
        marker.setAttribute('data-pdf-url', window.location.href);
        marker.textContent = 'PDF_REDIRECT:' + window.location.href;
        document.body.insertBefore(marker, document.body.firstChild);
      }
    html_elements_to_remove: [ ]
    html_classes_to_remove: [ ]
    html_classes_to_only_include:
      - ".mainhp"
    # Only include content from these classes if they exist, ignore if not found
    comment_blocks_to_remove: [ ]
      # Add domain-specific comment blocks here if needed
    exclude_urls:  # Domain-specific URLs to exclude
      - "**/sinformer/avisdedeces/**"
      - "**/sinformer/foreignexchange**"
      - "**/sinformer/loterie/**"
      - "**/sinformer/loterie-vert/**"
      - "**/dstv/sports-guide**"
      - "**/new-world-sport-guide**"
      # Add more domain-specific URLs to exclude here

  - domain: "devices.myt.mu"
    start_urls:
      - "https://devices.myt.mu/"
    js_code: |
      document.querySelectorAll('header, footer, nav, aside, .sidebar, .navbar, .header, .footer, style, script').forEach(el => el.remove());
    html_elements_to_remove: [ ]
    html_classes_to_remove: [ ]
    comment_blocks_to_remove:
      - [ "<!-- ADD SIDEBAR HERE -->", "<!-- end section -->" ]

    html_classes_to_only_include: [ ]
    exclude_urls: [ ]

  - domain: "esimtravel.myt.mu"
    start_urls:
      - "https://esimtravel.myt.mu/"
    js_code: |
      (async () => {
      document.querySelectorAll('p.text-font-text.text-esim_blue_light').forEach(v => v.textContent.includes('View More') && v.click?.());
      await new Promise(r => setTimeout(r, 1000));
      document.querySelectorAll('.p-panel-header').forEach(h => h.click?.());
      await new Promise(r => setTimeout(r, 2000));
      document.body.insertAdjacentHTML('beforeend', '<div class="js-execution-complete">JS code executed</div>');
      })();
    wait_for: "js:() => document.querySelectorAll('.js-execution-complete').length > 0"
    html_elements_to_remove: [ ]
    html_classes_to_remove: [ ]
    comment_blocks_to_remove: [ ]
    html_classes_to_only_include: [ ]
    exclude_urls: [ ]

#  - domain: "www.myt.mu"
#    start_urls:
#      - "https://www.myt.mu/business/"
#    js_code: |
#      // Remove unwanted elements
#      document.querySelectorAll('header, footer, nav, aside, .sidebar, .navbar, .header, .footer, style, script').forEach(el => el.remove());
#
#      // Detect if we're on a PDF page and add metadata
#      if (window.location.href.includes('.pdf')) {
#        const marker = document.createElement('div');
#        marker.id = 'pdf-redirect-marker';
#        marker.setAttribute('data-pdf-url', window.location.href);
#        marker.textContent = 'PDF_REDIRECT:' + window.location.href;
#        document.body.insertBefore(marker, document.body.firstChild);
#      }
#    html_elements_to_remove: [ ]
#    html_classes_to_remove: [ ]
#    html_classes_to_only_include:
#      - ".mainhp"
#    comment_blocks_to_remove: [ ]
#    exclude_urls:  # Domain-specific URLs to exclude
#      - "**/sinformer/avisdedeces/**"
#      - "**/sinformer/foreignexchange**"
#      - "**/sinformer/loterie/**"
#      - "**/sinformer/loterie-vert/**"
#      - "**/dstv/sports-guide**"
#      - "**/new-world-sport-guide**"
#      # Add more domain-specific URLs to exclude here


# Cost tracking and pricing configuration
cost_tracking:
  enabled: true
  output_file: "semantic_queue/cost_log.txt"
  
  # Pricing per 1M tokens in USD
  pricing:
    gemini:
      gemini-2.5-flash:
        free_tier:
          input: 0.0
          output: 0.0
        paid_tier:
          input: 0.30
          output: 2.50
    
    openai:
      gpt-4o-mini:
        input: 0.15
        output: 0.60
      gpt-4o:
        input: 2.50
        output: 10.00
      gpt-4-turbo:
        input: 10.00
        output: 30.00
    
    azure:
      gpt-4o-mini:
        input: 0.15
        output: 0.60
      gpt-4o:
        input: 2.50
        output: 10.00
